{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a03c5a0d",
   "metadata": {},
   "source": [
    "# FIN41910 Green Data Science: Portfolio Decarbonisation\n",
    "\n",
    " Rohan Kuntoji - 22202093"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cce9895a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pypfopt.efficient_frontier import EfficientFrontier\n",
    "from pypfopt.expected_returns import mean_historical_return\n",
    "from pypfopt.risk_models import CovarianceShrinkage\n",
    "from pypfopt import base_optimizer\n",
    "# from pypfopt import objective_functions\n",
    "import cvxpy as cp\n",
    "from pypfopt import base_optimizer\n",
    "import math\n",
    "# from pypfopt.exceptions import OptimizationError\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "690ee045",
   "metadata": {
    "code_folding": [
     17,
     26,
     40,
     54,
     67,
     88,
     113,
     129,
     142,
     155,
     199,
     239,
     273,
     300,
     322,
     345,
     366,
     388,
     404,
     427,
     445,
     465,
     467,
     476,
     481,
     506,
     583,
     631,
     682,
     715,
     808
    ],
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "class PortfolioDecarbonisation:\n",
    "\n",
    "    def __init__(self, filePath, risk_free_rate=0.0009):\n",
    "        \"\"\"\n",
    "        Initialise the class with a file path (pointing to the data source) \n",
    "        & risk-free rate (in decimal format)\n",
    "        \n",
    "\n",
    "        Parameters:\n",
    "            filePath (str): path to the Excel file\n",
    "            risk_free_rate (float): Risk-free rate. Defaults to 0.0009 (0.09%)\n",
    "        \"\"\"\n",
    "        self.filePath = filePath\n",
    "        self.risk_free_rate = risk_free_rate\n",
    "\n",
    "    def load_excel_data(self, sheetname, skiprows=None):\n",
    "        \"\"\"\n",
    "        Load an excel file with given filename, sheetname and skiprows\n",
    "\n",
    "        Parameters:\n",
    "            sheetname (str): Sheetname in the Excel file\n",
    "            skiprows (list): List of rows to skip from top. None by default\n",
    "\n",
    "        Returns:\n",
    "            DataFrame: A pandas DataFrame containing the data from the Excel file.\n",
    "        \"\"\"\n",
    "        return pd.read_excel(self.filePath, sheet_name=sheetname, skiprows=skiprows)\n",
    "\n",
    "    def rename_dataframe_columns(self, df, column_mapping):\n",
    "        \"\"\"\n",
    "        Rename the columns in a DataFrame based on a mapping\n",
    "\n",
    "        Parameters:\n",
    "            df (DataFrame): DataFrame to be renamed\n",
    "            column_mapping (dict): A dictionary mapping old column names to new column names\n",
    "\n",
    "        Returns:\n",
    "            DataFrame: The DataFrame with renamed columns.\n",
    "        \"\"\"\n",
    "        df.rename(columns=column_mapping, inplace=True)\n",
    "        return df\n",
    "\n",
    "    def fix_unnamed_columns(self, df):\n",
    "        \"\"\"\n",
    "        Fix 'Unnamed' columns in the dataframe\n",
    "\n",
    "        Parameters:\n",
    "            dataframe (DataFrame): The pandas DataFrame to be processed.\n",
    "\n",
    "        Returns:\n",
    "            DataFrame: The DataFrame with fixed 'Unnamed' columns.\n",
    "        \"\"\"\n",
    "        df.columns = df.columns.to_series().mask(lambda x: x.str.startswith('Unnamed')).ffill()\n",
    "        return df\n",
    "\n",
    "    def create_multi_index(self, df):\n",
    "        \"\"\"\n",
    "        Create MultiIndex df from the given df.\n",
    "\n",
    "        Parameters:\n",
    "            df (DataFrame): The pandas DataFrame to be processed.\n",
    "\n",
    "        Returns:\n",
    "            DataFrame: The MultiIndex DataFrame.\n",
    "        \"\"\"\n",
    "        copy_df = df.copy()\n",
    "        copy_df.drop(['Dates'], axis=1, inplace=True)\n",
    "        multi_index = pd.MultiIndex.from_arrays([copy_df.columns, copy_df.iloc[0].values])\n",
    "\n",
    "        df = df.drop([0]).reset_index(drop=True)\n",
    "        df['Dates'] = pd.to_datetime(df['Dates'], errors='coerce').dt.strftime('%Y-%m-%d')\n",
    "        df.set_index(df['Dates'], inplace=True)\n",
    "        df.drop(['Dates'], axis=1, inplace=True)\n",
    "        df.columns = multi_index\n",
    "        return df\n",
    "    \n",
    "    def _preprocess_data(self, df, new_columns, selected_columns=None):\n",
    "        \"\"\"\n",
    "        Generic method to process financial data, emission data and ESG Score data\n",
    "\n",
    "        Parameters:\n",
    "            df (DataFrame): DataFrame to be processed\n",
    "            new_columns (list): Column names for the DataFrame\n",
    "            selected_columns (list): Columns to select from the processed DataFrame. None by default\n",
    "\n",
    "        Returns:\n",
    "            DataFrame: Processed DataFrame\n",
    "        \"\"\"\n",
    "        df = df.stack(0, dropna=False)\n",
    "        df.rename_axis(index=['Dates', 'Ticker'], inplace=True)\n",
    "        df = df.swaplevel()\n",
    "        df = df.sort_values(['Ticker', 'Dates'], ascending=[True, True])\n",
    "        columns_to_convert = df.columns\n",
    "        df[columns_to_convert] = df[columns_to_convert].apply(pd.to_numeric, errors='coerce')\n",
    "        df.columns = new_columns\n",
    "        \n",
    "        if selected_columns is not None:\n",
    "            df = df[selected_columns]\n",
    "            \n",
    "        return df\n",
    "\n",
    "    def process_financial_data(self, df):\n",
    "        \"\"\"\n",
    "        Process the financial data df to final form.\n",
    "\n",
    "        Parameters:\n",
    "            df (DataFrame): The pandas DataFrame to be processed.\n",
    "\n",
    "        Returns:\n",
    "            DataFrame: The final DataFrame.\n",
    "        \"\"\"\n",
    "        new_columns = ['MarketCap', 'Revenue', 'TotalAssets', 'Total Equity']\n",
    "        selected_columns = ['MarketCap', 'Revenue']\n",
    "        return self._preprocess_data(df, new_columns, selected_columns)\n",
    "\n",
    "    def process_emission_data(self, df):\n",
    "        \"\"\"\n",
    "        Process the emission data dataframe to final form\n",
    "\n",
    "        Parameters:\n",
    "            df (DataFrame): The pandas DataFrame to be processed\n",
    "\n",
    "        Returns:\n",
    "            DataFrame: The final DataFrame.\n",
    "        \"\"\"\n",
    "        new_columns = ['Scope1', 'Scope2Location', 'Scope2Market', 'Scope3']\n",
    "        return self._preprocess_data(df, new_columns)\n",
    "\n",
    "    def process_esg_score_data(self, df):\n",
    "        \"\"\"\n",
    "        Process the ESG Score data df to final form.\n",
    "\n",
    "        Parameters:\n",
    "            df (DataFrame): The pandas DataFrame to be processed.\n",
    "\n",
    "        Returns:\n",
    "            DataFrame: The final DataFrame.\n",
    "        \"\"\"\n",
    "        new_columns = ['ESG Score', 'Environmental Score', 'Governance Score', 'Social Score']\n",
    "        return self._preprocess_data(df, new_columns)\n",
    "\n",
    "    def data_etl(self, sheetnames=['Company List', 'Financial Data', 'GHG Emission', 'ESG Score'],\n",
    "                     filter_date='2022-12-31'):\n",
    "        \"\"\"\n",
    "        Load, process, and merge data from multiple sheets of an Excel file.\n",
    "\n",
    "        Parameters:\n",
    "            sheetnames (list): A list of sheet names in the Excel file\n",
    "            filter_date (str): A date string in 'yyyy-mm-dd' format to filter the final DataFrame\n",
    "\n",
    "        Returns:\n",
    "            DataFrame: A pandas DataFrame containing processed data from all specified sheets\n",
    "        \"\"\"\n",
    "        dataframes = {}\n",
    "        for sheetname in sheetnames:\n",
    "            df = self.load_excel_data(sheetname, skiprows=[0, 1, 2])\n",
    "            df = self.fix_unnamed_columns(df)\n",
    "            df.columns.values[0] = 'Dates'\n",
    "            df = self.create_multi_index(df)\n",
    "            dataframes[sheetname] = df\n",
    "\n",
    "        # process each dataframe individually\n",
    "        R3000list = self.rename_dataframe_columns(dataframes['Company List'], {'BBG Ticker': 'Ticker'})\n",
    "        fin_panel = self.process_financial_data(dataframes['Financial Data'])\n",
    "        emission_panel = self.process_emission_data(dataframes['GHG Emission'])\n",
    "        esg_score_panel = self.process_esg_score_data(dataframes['ESG Score'])\n",
    "\n",
    "        # merge all processed dataframes\n",
    "        df1 = pd.merge(emission_panel, esg_score_panel, how='outer', on=['Ticker', 'Dates'])\n",
    "        df2 = pd.merge(df1, fin_panel, how='outer', on=['Ticker', 'Dates'])\n",
    "        # Filter for the specified date\n",
    "        final_data = df2[df2.index.get_level_values('Dates') == filter_date]\n",
    "\n",
    "        # Check for missing values in 'Scope1', 'Scope2Location', 'Revenue'\n",
    "        drop_list = final_data[final_data[['Scope1', 'Scope2Location', 'Revenue']].isna().any(axis=1)]\n",
    "        drop_list.reset_index(drop=False, inplace=True)\n",
    "        drop_list = drop_list['Ticker']\n",
    "        # Drop companies with missing values\n",
    "        final_data = final_data.drop(drop_list, level=0, axis=0)\n",
    "\n",
    "        return final_data\n",
    "\n",
    "    def process_stock_price_data(self, sheetname='Stock', skiprows=[0, 1, 2]):\n",
    "        \"\"\"\n",
    "        Load and process stock price data from an Excel file.\n",
    "\n",
    "        Parameters:\n",
    "            sheetname (str): Sheetname in Excel file\n",
    "            skiprows (list): Skip first 3 rows\n",
    "\n",
    "        Returns:\n",
    "            DataFrame: Pandas DataFrame containing processed stock price data.\n",
    "        \"\"\"\n",
    "        stock_data = self.load_excel_data(sheetname, skiprows) # Load stock price data from the Excel file\n",
    "        # Fix 'Unnamed' columns\n",
    "        stock_data = self.fix_unnamed_columns(stock_data)\n",
    "        stock_data = stock_data.drop([0]).reset_index(drop=True)\n",
    "        stock_data.columns.values[0] = 'Dates'\n",
    "        # Create MultiIndex DataFrame\n",
    "        stock_data = self.create_multi_index(stock_data)\n",
    "\n",
    "        # Process the data\n",
    "        stock_data = stock_data.stack(0, dropna=False)\n",
    "        stock_data.rename_axis(index=['Dates', 'Ticker'], inplace=True)\n",
    "        stock_data = stock_data.swaplevel()\n",
    "        stock_data = stock_data.sort_values(['Ticker', 'Dates'], ascending=[True, True])\n",
    "        stock_data = stock_data.astype(float)\n",
    "        stock_data.columns = ['Closing Stock Price']\n",
    "        stock_closing_price = stock_data.unstack().T\n",
    "        stock_closing_price.reset_index(drop=False, inplace=True)\n",
    "        stock_closing_price.set_index('Dates', inplace=True)\n",
    "        stock_closing_price.drop('level_0', axis=1, inplace=True)\n",
    "        stock_closing_price.sort_index(axis=1, inplace=True)\n",
    "        ##### Checking for missing values\n",
    "        stock_closing_price = stock_closing_price.dropna(axis='columns')\n",
    "\n",
    "        return stock_closing_price\n",
    "    \n",
    "    def group_data_by_sector(self, financial_environmental_data, financial_stock_data):\n",
    "        \"\"\"\n",
    "        Group the processed data by sector and sort by MarketCap\n",
    "\n",
    "        Parameters:\n",
    "            financial_environmental_data (DataFrame): DataFrame containing the financial and environmental data\n",
    "            financial_stock_data (DataFrame): DataFrame containing the stock price data\n",
    "\n",
    "        Returns:\n",
    "            DataFrame: DataFrame grouped by 'GICS Sector' and 'Ticker' and sorted by 'MarketCap'\n",
    "        \"\"\"\n",
    "        market_cap = pd.DataFrame(financial_environmental_data['MarketCap'])\n",
    "        market_cap.reset_index(drop=False, inplace=True)\n",
    "        market_cap.drop('Dates', axis=1, inplace=True)\n",
    "        market_cap.set_index('Ticker', inplace=True)\n",
    "        temp_data = market_cap.T\n",
    "        R3000list = self.rename_dataframe_columns(self.load_excel_data('Company List'), {'BBG Ticker': 'Ticker'})\n",
    "        common_tickers = list(set(list(financial_stock_data.columns)) & set(list(temp_data.columns)))\n",
    "        temp_data = temp_data[common_tickers]\n",
    "        market_cap = temp_data.T.reset_index(drop=False)\n",
    "        companies_df = pd.merge(R3000list, market_cap, on='Ticker', how='inner')\n",
    "        companies_df.drop(['ISIN', 'Company'], axis=1, inplace=True)\n",
    "        sector_groups = pd.DataFrame(companies_df.groupby(['GICS Sector', 'Ticker'])['MarketCap'].mean()).sort_values(\n",
    "            ['GICS Sector', 'MarketCap'], ascending=[True, False]) # Q:RSK It was ascending=[True, False]\n",
    "\n",
    "        return sector_groups\n",
    "    \n",
    "    def get_random_tickers(self, df, n=5):\n",
    "        \"\"\"\n",
    "        Selects n random tickers from each sector in a DataFrame\n",
    "\n",
    "        Parameters:\n",
    "            df (DataFrame): Sector dataframe\n",
    "            n (int): The number of initial random tickers to select from each sector, defaults to 5\n",
    "\n",
    "        Returns:\n",
    "            DataFrame: A new DataFrame containing only the random tickers selected from each sector.\n",
    "        \"\"\"\n",
    "        np.random.seed(100)  \n",
    "        random_tickers = df.groupby(level=0).apply(lambda x: x.sample(n) if len(x) >= n else x).droplevel(0)\n",
    "        # If there are less than 100 tickers, randomly add more tickers from any sector\n",
    "        while len(random_tickers) < 100:\n",
    "            # Choose a sector (randomly)\n",
    "            sector = np.random.choice(df.index.get_level_values(0).unique())\n",
    "            # Choose a ticker from the sector that is not already in the list\n",
    "            additional_ticker = df.loc[sector].loc[~df.loc[sector].index.isin(random_tickers.index)].sample(1)\n",
    "            # Preserve the sector information\n",
    "            additional_ticker.index = pd.MultiIndex.from_tuples([(sector, additional_ticker.index[0])], names = [\"Sector\", \"Ticker\"])\n",
    "            # Add the chosen ticker to the list\n",
    "            random_tickers = pd.concat([random_tickers, additional_ticker])\n",
    "\n",
    "        return random_tickers\n",
    "    \n",
    "    def get_final_data(self, random_tickers, financial_environmental_data, financial_stock_data):\n",
    "        \"\"\"\n",
    "        Filters the financial and environmental data to include only the randomly selected tickers\n",
    "\n",
    "        Parameters:\n",
    "            random_tickers (DataFrame): DataFrame containing randomly selected tickers from each sector\n",
    "            financial_environmental_data (DataFrame): DataFrame containing the financial and environmental data\n",
    "            financial_stock_data (DataFrame): DataFrame containing the stock price data\n",
    "\n",
    "        Returns:\n",
    "            DataFrame: DataFrame containing financial, environmental, and sector information for the randomly selected tickers\n",
    "            DataFrame: DataFrame containing stock data and sector information for the randomly selected tickers\n",
    "        \"\"\"\n",
    "        R3000list = self.rename_dataframe_columns(self.load_excel_data('Company List'), {'BBG Ticker': 'Ticker'})\n",
    "        company_list = list(random_tickers.index.get_level_values('Ticker'))\n",
    "        df_final = financial_environmental_data[financial_environmental_data.index.get_level_values('Ticker').isin(company_list)]\n",
    "        df_final = pd.merge(df_final, R3000list[['Ticker', 'GICS Sector']], on='Ticker', how='left')\n",
    "        df_final['Carbon Intensity'] = (df_final['Scope1'] + df_final['Scope2Location'])/df_final['Revenue']\n",
    "        df_final.set_index('Ticker',inplace=True)\n",
    "        stock_prices = financial_stock_data[company_list]\n",
    "        stock_prices.sort_index(axis=1, inplace=True)\n",
    "        print(f'RSK: df_final: {df_final.head()}')\n",
    "        print(f'RSK: stock_prices: {stock_prices.head()}')\n",
    "\n",
    "        return df_final, stock_prices\n",
    "    \n",
    "    def get_descriptive_statistics(self, df_final, df_stock):\n",
    "        \"\"\"\n",
    "        Descriptive statistics for a given DataFrame\n",
    "\n",
    "        Parameters:\n",
    "            df_final (DataFrame): DataFrame for which to compute statistics\n",
    "            df_stock (DataFrame): Stock data DataFrame for which to compute statistics\n",
    "\n",
    "        Returns:\n",
    "            dict: Summary stats \n",
    "        \"\"\"\n",
    "        market_cap = df_final['MarketCap']\n",
    "        stats = {\n",
    "            'mean': market_cap.mean(),\n",
    "            'std_dev': market_cap.std(),\n",
    "            'min': market_cap.min(),\n",
    "            'max': market_cap.max(),\n",
    "            'median': market_cap.median(),\n",
    "            'mu': mean_historical_return(df_stock, frequency=12),\n",
    "            'S': CovarianceShrinkage(df_stock, frequency=12).ledoit_wolf()\n",
    "        }\n",
    "\n",
    "        return stats\n",
    "    \n",
    "    def get_benchmark_portfolio(self, df_final, mu):\n",
    "        \"\"\"\n",
    "        Calculate benchmark portfolio & its weights based on market capitalization ratios.\n",
    "\n",
    "        Parameters:\n",
    "            df_final (DataFrame): Dataframe containing financial and environmental data for the 100 stocks\n",
    "            mu (Series): Expected returns for all stocks\n",
    "            \n",
    "        Returns:\n",
    "            DataFrame: Benchmark portfolio with weights, expected stock returns and scores\n",
    "        \"\"\"\n",
    "        market_cap = df_final[['GICS Sector','MarketCap']]\n",
    "        benchmark_portfolio = pd.DataFrame()\n",
    "        benchmark_portfolio['GICS Sector'] = market_cap['GICS Sector']\n",
    "        benchmark_portfolio['Weights'] = market_cap['MarketCap']/market_cap['MarketCap'].sum()\n",
    "        benchmark_portfolio['ExpStockReturns'] = mu * benchmark_portfolio['Weights']\n",
    "        portfolio_scores = ['Carbon Intensity', 'ESG Score', 'Environmental Score', 'Social Score', 'Governance Score']\n",
    "        for score in portfolio_scores:\n",
    "            benchmark_portfolio[f'Exp{score}'] = df_final[score] * benchmark_portfolio['Weights']\n",
    "        print(f'RSK: benchmark_portfolio: {benchmark_portfolio.head()}')\n",
    "        return benchmark_portfolio\n",
    "    \n",
    "    def get_portfolio_performance(self, portfolio_weights, mu, S):\n",
    "        \"\"\"\n",
    "        Calculate portfolio performance including expected return, volatility, sharpe ratio, and number of companies\n",
    "\n",
    "        Parameters:\n",
    "            portfolio_weights (DataFrame): Portfolio weights for each stock\n",
    "            mu (Series): Expected returns for all stocks\n",
    "            S (DataFrame): Covariance matrix of stock returns\n",
    "            \n",
    "        Returns:\n",
    "            dict: A dictionary containing performance metrics\n",
    "        \"\"\"\n",
    "        performance = base_optimizer.portfolio_performance(portfolio_weights['Weights'], mu, S, verbose=True,\n",
    "                                                              risk_free_rate=self.risk_free_rate)\n",
    "        return {\n",
    "            'Annualised_ExpReturn': performance[0]*100,\n",
    "            'Annualised_Volatility': performance[1]*100,\n",
    "            'Sharpe_Ratio': performance[2],\n",
    "            'Num_Companies': portfolio_weights[portfolio_weights['Weights'] > 0].count()['Weights']\n",
    "        }\n",
    "\n",
    "    def print_portfolio_stats(self, portfolio_perf):\n",
    "        \"\"\"\n",
    "        Print portfolio performance metrics.\n",
    "\n",
    "        Parameters:\n",
    "            portfolio_perf (dict): Portfolio performance metrics\n",
    "            \n",
    "        Returns:\n",
    "            None\n",
    "        \"\"\"\n",
    "        print(\"\\n\")\n",
    "        print(f\"Annualised Expected Return of Portfolio = {portfolio_perf['Annualised_ExpReturn']:.2f}%\")\n",
    "        print(f\"Annualised Volatility of Portfolio = {portfolio_perf['Annualised_Volatility']:.2f}%\")\n",
    "        print(f\"Annualised Sharpe Ratio of Portfolio = {portfolio_perf['Sharpe_Ratio']}\")\n",
    "        print(f\"No. of companies constituting the Portfolio = {portfolio_perf['Num_Companies']}\")\n",
    "\n",
    "    def get_portfolio_scores(self, portfolio_weights, df_final, is_benchmark=False):\n",
    "        \"\"\"\n",
    "        Calculate ESG scores for the portfolio\n",
    "\n",
    "        Parameters:\n",
    "            portfolio_weights (DataFrame): Portfolio weights for each stock\n",
    "            df_final (DataFrame): Final DataFrame containing all financial and environmental data of 100 stocks\n",
    "            is_benchmark (bool, optional): Whether the portfolio is a benchmark portfolio. Defaults to False.\n",
    "            \n",
    "        Returns:\n",
    "            dict: A dictionary containing portfolio ESG scores\n",
    "        \"\"\"\n",
    "        portfolio_scores = ['Carbon Intensity', 'ESG Score', 'Environmental Score', 'Social Score', 'Governance Score']\n",
    "        scores = {}\n",
    "        if is_benchmark:\n",
    "            for score in portfolio_scores:\n",
    "                modified_txt = \"Exp\" + score\n",
    "                scores[score] = portfolio_weights[modified_txt].sum()\n",
    "        else:  # If decarbonised portfolio\n",
    "            for score in portfolio_scores:\n",
    "                scores[score] = (df_final[score] * portfolio_weights).sum()\n",
    "        return scores\n",
    "\n",
    "    def print_portfolio_scores(self, portfolio_scores):\n",
    "        \"\"\"\n",
    "        Print ESG scores for the portfolio.\n",
    "\n",
    "        Parameters:\n",
    "            portfolio_scores (dict): Portfolio ESG scores\n",
    "            \n",
    "        Returns:\n",
    "            None\n",
    "        \"\"\"\n",
    "        print(\"\\n\")\n",
    "        print(f\"Portfolio Carbon Intensity =  {portfolio_scores['Carbon Intensity']:.4f} CO2 (t)/ revenue ($mn)\")\n",
    "        print(f\"Portfolio ESG Score =  {portfolio_scores['ESG Score']:.2f}\")\n",
    "        print(f\"Portfolio Environmental Score = {portfolio_scores['Environmental Score']:.2f}\")\n",
    "        print(f\"Portfolio Social Score = {portfolio_scores['Social Score']:.2f}\")\n",
    "        print(f\"Portfolio Governance Score = {portfolio_scores['Governance Score']:.2f}\")\n",
    "        print(\"\\n\")\n",
    "    \n",
    "    def market_cap_portfolio(self, df_final, mu, S):\n",
    "        \"\"\"\n",
    "        Calculate market cap weighted portfolio, its performance metrics, and ESG scores\n",
    "\n",
    "        Args:\n",
    "            df_final (DataFrame): Final DataFrame containing all financial and environmental data of 100 stocks\n",
    "            mu (Series): Expected returns for all stocks\n",
    "            S (DataFrame): Covariance matrix of stock returns\n",
    "            \n",
    "        Returns:\n",
    "            Tuple: A tuple containing portfolio weights DataFrame, performance dictionary, and ESG scores dictionary\n",
    "        \"\"\"\n",
    "        benchmark_portfolio = self.get_benchmark_portfolio(df_final, mu)\n",
    "        benchmark_performance = self.get_portfolio_performance(benchmark_portfolio, mu, S)\n",
    "        benchmark_scores = self.get_portfolio_scores(benchmark_portfolio, df_final, is_benchmark=True)\n",
    "        self.print_portfolio_stats(benchmark_performance)\n",
    "        self.print_portfolio_scores(benchmark_scores)\n",
    "        return benchmark_portfolio, benchmark_performance, benchmark_scores\n",
    "        \n",
    "    def _objective_value(self, w, obj):\n",
    "        if isinstance(w, np.ndarray):\n",
    "            if np.isscalar(obj):\n",
    "                return obj\n",
    "            elif np.isscalar(obj.value):\n",
    "                return obj.value\n",
    "            else:\n",
    "                return obj.value.item()\n",
    "        else:\n",
    "            return obj\n",
    "\n",
    "    def ex_ante_tracking_error(self, w, cov_matrix, benchmark_weights):\n",
    "        \"\"\"\n",
    "        Computes ex-ante tracking error of portfolio's returns \n",
    "        with the benchmark's returns.\n",
    "\n",
    "        Parameters:\n",
    "            w (np.array): Weights of the selected portfolio\n",
    "            cov_matrix (np.array): Covariance matrix of the returns of the stocks\n",
    "            benchmark_weights (np.array): Weights of the benchmark portfolio\n",
    "            \n",
    "        Returns:\n",
    "            float: A float value representing the tracking error\n",
    "        \"\"\"\n",
    "        relative_weights = w - benchmark_weights\n",
    "        variance = cp.quad_form(relative_weights, cov_matrix)\n",
    "        tracking_error = math.sqrt(variance)\n",
    "        return self._objective_value(w, tracking_error)\n",
    "    \n",
    "    def sector_balance(self, final_data, random_tickers):\n",
    "        \"\"\"\n",
    "        Balance the sector composition for the portfolio.\n",
    "\n",
    "        Parameters:\n",
    "            final_data (DataFrame): DataFrame containing all financial and environmental data\n",
    "            random_tickers (DataFrame): DataFrame containing random stock tickers\n",
    "            \n",
    "        Returns:\n",
    "            Tuple: A tuple containing sector mapping dictionary, lower bound for each sector, and upper bound for each sector\n",
    "        \"\"\"\n",
    "        ticker_counts = random_tickers.groupby('GICS Sector').size()/100\n",
    "        # Sector Mapping as a Dictionary\n",
    "        sector_mapping = final_data.reset_index(drop=False)[['GICS Sector','Ticker']]\n",
    "        sector_mapping.set_index('Ticker',inplace=True)\n",
    "        sector_mapping_dict = sector_mapping.to_dict()['GICS Sector']\n",
    "        lower = 0.7    # Lower Bound of change (-30%)\n",
    "        upper = 1.3    # Upper Bound of change (+30%)\n",
    "        sector_lower = {}\n",
    "        sector_upper = {}\n",
    "        for sector, count in ticker_counts.items():\n",
    "            sector_lower[sector] = count * lower\n",
    "            sector_upper[sector] = count * upper\n",
    "        return sector_mapping_dict, sector_lower, sector_upper\n",
    "         \n",
    "    def decarbonised_portfolio(self, total_initial_carbon_intensity, intensity_reduction_rate, base_optimizer, stock_prices, \n",
    "                               mu, S, carbon_intensity, df_final, benchmark_weights, random_tickers=None, \n",
    "                               is_sector_balance_portfolio = False ):\n",
    "        \"\"\"\n",
    "        Creates a portfolio with decarbonisation constraints. It takes the maximum tracking error, \n",
    "        a target carbon intensity and an optimiser as inputs and returns a DataFrame with the optimal portfolio \n",
    "        weights that minimises the portfolio's carbon intensity subject to the constraints\n",
    "\n",
    "        Parameters:\n",
    "            total_initial_carbon_intensity (float):, initial portfolio carbon intensity\n",
    "            intensity_reduction_rate (float): proportion to reduce the initial portfolio carbon intensity by to achieve target carbon intensity\n",
    "            base_optimizer (object): instance of the BaseConvexOptimizer class to solve the optimisation problem\n",
    "            stock_prices (DataFrame): DataFrame containing stock prices data\n",
    "            mu (np.array): Expected returns of each stock\n",
    "            S (np.array): Covariance matrix of the returns of the stocks\n",
    "            carbon_intensity (np.array): Carbon intensity of each stock\n",
    "            df_final (DataFrame): Final DataFrame containing all financial and environmental data\n",
    "            benchmark_weights (np.array): Weights of the benchmark portfolio\n",
    "            random_tickers (list, optional): List of random tickers chosen for portfolio\n",
    "            is_sector_balance_portfolio (bool): Flag to check if it's a decarbonised portfolio with sector balance adjustment\n",
    "\n",
    "        Returns:\n",
    "            DC_weights (DataFrame): Weights of the decarbonised portfolio\n",
    "            DC_performance (dict): Performance of the decarbonised portfolio\n",
    "            DC_scores (dict): Scores of the decarbonised portfolio\n",
    "        \"\"\"\n",
    "        max_tracking_error = 0.01 # Setting up maximum tracking error at 1%\n",
    "        # Target carbon intensity to be intensity_rate proportion of initial value \n",
    "        target_carbon_intensity = total_initial_carbon_intensity * (1-intensity_reduction_rate)\n",
    "\n",
    "        # Create the EfficientFrontier object\n",
    "        efficient_dc = base_optimizer.BaseConvexOptimizer(\n",
    "            n_assets=len(stock_prices.columns),\n",
    "            tickers=stock_prices.columns,\n",
    "            weight_bounds=(0, 1)\n",
    "        )\n",
    "        sector_mapping_dict = None\n",
    "        sector_lower = None\n",
    "        sector_upper = None\n",
    "        \n",
    "        # Apply relevant constraints (as per the suggested guide) for sector balance adjustment portfolio\n",
    "        if is_sector_balance_portfolio:\n",
    "            efficient_dc.add_constraint(lambda w: w @ carbon_intensity == target_carbon_intensity)\n",
    "            efficient_dc.add_constraint(lambda w: cp.sum(w) == 1)\n",
    "            efficient_dc.add_constraint(lambda w: self.ex_ante_tracking_error(w, S, benchmark_weights) <= max_tracking_error)\n",
    "            sector_mapping_dict, sector_lower, sector_upper = self.sector_balance(df_final, random_tickers)\n",
    "            efficient_dc.add_sector_constraints(sector_mapper = sector_mapping_dict, \n",
    "                               sector_lower = sector_lower,  # Current mapping * 0.7 (-30%)\n",
    "                               sector_upper = sector_upper)  # Current mapping * 1.3 (+30%)\n",
    "        else:\n",
    "            # Add the tracking error constraint\n",
    "            efficient_dc.add_constraint(lambda w: self.ex_ante_tracking_error(w, S, benchmark_weights) <= max_tracking_error)\n",
    "            # Adding Carbon Constraint\n",
    "            efficient_dc.add_constraint(lambda w: w @ carbon_intensity == target_carbon_intensity)\n",
    "            # Adding constraint for weights to sum to 1\n",
    "            efficient_dc.add_constraint(lambda w: cp.sum(w) == 1)\n",
    "        \n",
    "        # Adding the decarbonisation objective function\n",
    "        efficient_dc.convex_objective(lambda w: w @ carbon_intensity, weights_sum_to_one=True)\n",
    "\n",
    "        # Compute the optimal weights\n",
    "        cleaned_weights_dcp = efficient_dc.clean_weights()\n",
    "        DC_weights = pd.DataFrame(cleaned_weights_dcp, columns=cleaned_weights_dcp.keys(), index=['Weights']).T\n",
    "        DC_weights['GICS Sector'] = df_final['GICS Sector']\n",
    "        # Calculate and print portfolio performance and scores\n",
    "        DC_performance = self.get_portfolio_performance(DC_weights, mu, S)\n",
    "        DC_scores = self.get_portfolio_scores(DC_weights['Weights'], df_final, is_benchmark=False)\n",
    "        self.print_portfolio_stats(DC_performance)\n",
    "        self.print_portfolio_scores(DC_scores)\n",
    "        \n",
    "        return DC_weights, DC_performance, DC_scores\n",
    "\n",
    "    def mean_variance_efficient_portfolio(self, mu, S, df_final, total_initial_carbon_intensity, carbon_intensity, \n",
    "                                          intensity_reduction_rate, is_decarbonised=False):\n",
    "        \"\"\"\n",
    "        Creates a mean-variance efficient portfolio with or without decarbonisation constraints. \n",
    "        It takes expected returns, a covariance matrix, a DataFrame of processed data and benchmark weights as inputs \n",
    "        and returns a DataFrame with the optimal portfolio weights that maximise the Sharpe ratio\n",
    "\n",
    "        Parameters:\n",
    "            mu (np.array): Expected returns of each stock.\n",
    "            S (np.array): Covariance matrix of the returns of the stocks.\n",
    "            df_final (DataFrame): Final DataFrame after cleaning and pre-processing.\n",
    "            total_initial_carbon_intensity (float): Initial portfolio carbon intensity.\n",
    "            carbon_intensity (np.array): Carbon intensity of each stock.\n",
    "            intensity_reduction_rate (float): proportion to reduce the initial portfolio carbon intensity by to achieve target carbon intensity\n",
    "            is_decarbonised (bool): Whether to include decarbonisation constraints.\n",
    "\n",
    "        Returns:\n",
    "            MVP_weights (DataFrame): Weights of the mean-variance efficient portfolio.\n",
    "            MVP_perf (dict): Performance of the mean-variance efficient portfolio.\n",
    "            MVP_scores (dict): Scores of the mean-variance efficient portfolio.\n",
    "        \"\"\"\n",
    "        efficient_frontier = EfficientFrontier(mu, S, weight_bounds=(0, 1))\n",
    "        if is_decarbonised:\n",
    "            target_carbon_intensity = total_initial_carbon_intensity * (1-intensity_reduction_rate)\n",
    "            efficient_frontier.add_constraint(lambda w: w @ carbon_intensity == target_carbon_intensity)\n",
    "            # efficient_frontier.add_constraint(lambda w: w >= 0)\n",
    "            efficient_frontier.add_constraint(lambda w: cp.sum(w) == 1)\n",
    "            raw_weights = efficient_frontier.max_sharpe(risk_free_rate=self.risk_free_rate)\n",
    "        else:\n",
    "            # efficient_frontier.add_constraint(lambda w: w >= 0)\n",
    "            # efficient_frontier.add_constraint(lambda w: w <= 1)\n",
    "            efficient_frontier.add_constraint(lambda w: cp.sum(w) == 1)\n",
    "            raw_weights = efficient_frontier.max_sharpe(risk_free_rate=self.risk_free_rate)\n",
    "\n",
    "        cleaned_weights = efficient_frontier.clean_weights()\n",
    "        MVP_weights = pd.DataFrame(cleaned_weights, columns=cleaned_weights.keys(), index=['Weights']).T\n",
    "        MVP_weights['GICS Sector'] = df_final['GICS Sector']\n",
    "        MVP_perf = self.get_portfolio_performance(MVP_weights, mu, S)\n",
    "        MVP_scores = self.get_portfolio_scores(MVP_weights['Weights'], df_final, is_benchmark=False)\n",
    "        self.print_portfolio_stats(MVP_perf)\n",
    "        self.print_portfolio_scores(MVP_scores)\n",
    "\n",
    "        return MVP_weights, MVP_perf, MVP_scores\n",
    "\n",
    "    def create_esg_performance_df(self, benchmark_scores, dcp_1_scores, dcp_2_scores, dcp_3_scores, dcp_4_scores, \n",
    "                                  mvp_scores, mvp_dcp_5_scores, portfolios_list):\n",
    "        \"\"\"\n",
    "        Creates a DataFrame with the ESG performance of different portfolios. It takes scores of \n",
    "        different portfolios and a list of portfolio names as inputs and returns a DataFrame with the ESG scores.\n",
    "\n",
    "        Parameters:\n",
    "            benchmark_scores (dict): Scores of the benchmark portfolio.\n",
    "            dcp_1_scores (dict): Scores of decarbonised portfolio 1.\n",
    "            dcp_2_scores (dict): Scores of decarbonised portfolio 2.\n",
    "            dcp_3_scores (dict): Scores of decarbonised portfolio 3.\n",
    "            dcp_4_scores (dict): Scores of decarbonised portfolio 4 (with sector balance adjustment).\n",
    "            mvp_scores (dict): Scores of the mean-variance portfolio.\n",
    "            mvp_dcp_5_scores (dict): Scores of decarbonised portfolio 5 (MVP with decarbonisation constraints).\n",
    "            portfolios_list (list): Names of the portfolios.\n",
    "\n",
    "        Returns:\n",
    "            Portfolio_ESGPerf (DataFrame): ESG performance of the portfolios.\n",
    "        \"\"\"\n",
    "        Portfolio_ESGPerf = pd.DataFrame(columns=['Mean Annual Emission', 'Avg ESG Score', 'Avg Environment Score',\n",
    "                                                  'Avg Governance Score', 'Avg Social Score'], index=portfolios_list)\n",
    "        Portfolio_ESGPerf['Mean Annual Emission'] = [benchmark_scores['Carbon Intensity'], dcp_1_scores['Carbon Intensity'], \n",
    "                                                     dcp_2_scores['Carbon Intensity'], dcp_3_scores['Carbon Intensity'], \n",
    "                                                     dcp_4_scores['Carbon Intensity'], mvp_scores['Carbon Intensity'], \n",
    "                                                     mvp_dcp_5_scores['Carbon Intensity']]\n",
    "        Portfolio_ESGPerf['Avg ESG Score'] = [benchmark_scores['ESG Score'], dcp_1_scores['ESG Score'], \n",
    "                                                     dcp_2_scores['ESG Score'], dcp_3_scores['ESG Score'], \n",
    "                                                     dcp_4_scores['ESG Score'], mvp_scores['ESG Score'], \n",
    "                                                     mvp_dcp_5_scores['ESG Score']]\n",
    "        Portfolio_ESGPerf['Avg Environment Score'] = [benchmark_scores['Environmental Score'], dcp_1_scores['Environmental Score'], \n",
    "                                                     dcp_2_scores['Environmental Score'], dcp_3_scores['Environmental Score'], \n",
    "                                                     dcp_4_scores['Environmental Score'], mvp_scores['Environmental Score'], \n",
    "                                                     mvp_dcp_5_scores['Environmental Score']]\n",
    "        Portfolio_ESGPerf['Avg Governance Score'] = [benchmark_scores['Governance Score'], dcp_1_scores['Governance Score'], \n",
    "                                                     dcp_2_scores['Governance Score'], dcp_3_scores['Governance Score'], \n",
    "                                                     dcp_4_scores['Governance Score'], mvp_scores['Governance Score'], \n",
    "                                                     mvp_dcp_5_scores['Governance Score']]\n",
    "        Portfolio_ESGPerf['Avg Social Score'] = [benchmark_scores['Social Score'], dcp_1_scores['Social Score'], \n",
    "                                                     dcp_2_scores['Social Score'], dcp_3_scores['Social Score'], \n",
    "                                                     dcp_4_scores['Social Score'], mvp_scores['Social Score'], \n",
    "                                                     mvp_dcp_5_scores['Social Score']]\n",
    "\n",
    "        return Portfolio_ESGPerf\n",
    "    \n",
    "    def sector_analysis(self, benchmark_portfolio, DCP1_weights, DCP2_weights, DCP3_weights, DCP4_weights, MVP_weights, \n",
    "                        DCP5_weights):\n",
    "        \"\"\"\n",
    "        Creates DataFrames with the sector composition of different portfolios. It takes portfolio \n",
    "        weights as inputs and returns a DataFrame with the sector composition.\n",
    "\n",
    "        Parameters:\n",
    "            benchmark_portfolio (DataFrame): Weights of the benchmark portfolio\n",
    "            DCP1_weights (DataFrame): Weights of decarbonised portfolio 1\n",
    "            DCP2_weights (DataFrame): Weights of decarbonised portfolio 2\n",
    "            DCP3_weights (DataFrame): Weights of decarbonised portfolio 3\n",
    "            DCP4_weights (DataFrame): Weights of decarbonised portfolio 4\n",
    "            MVP_weights (DataFrame): Weights of the mean-variance portfolio\n",
    "            DCP5_weights (DataFrame): Weights of decarbonised portfolio 5\n",
    "\n",
    "        Returns:\n",
    "            sector_composition (DataFrame): Sector composition of the portfolios\n",
    "            sector_composition_grouped (DataFrame): Grouped sector composition of the portfolios\n",
    "        \"\"\"\n",
    "        sector_composition = benchmark_portfolio[['GICS Sector','Weights']].copy()\n",
    "        sector_composition.rename(columns={'Weights':'Benchmark'},inplace=True)\n",
    "        sector_composition['DC_Portfolio1'] = DCP1_weights['Weights']\n",
    "        sector_composition['DC_Portfolio2'] = DCP2_weights['Weights']\n",
    "        sector_composition['DC_Portfolio3'] = DCP3_weights['Weights']\n",
    "        sector_composition['DC_Portfolio4'] = DCP4_weights['Weights']\n",
    "        sector_composition['MV_Portfolio']  = MVP_weights['Weights']\n",
    "        sector_composition['DC_Portfolio5'] = DCP5_weights['Weights']\n",
    "        sector_composition_grouped = sector_composition.groupby('GICS Sector')['Benchmark','DC_Portfolio1','DC_Portfolio2','DC_Portfolio3','DC_Portfolio4','MV_Portfolio','DC_Portfolio5'].sum()\n",
    "        return sector_composition, sector_composition_grouped\n",
    "    \n",
    "    def create_and_analyze_portfolios(self, base_optimizer, num_random_tickers_each_sector, portfolios_list):\n",
    "        \"\"\"\n",
    "        Generates and analyzes various types of portfolios, including benchmark and decarbonised portfolios. \n",
    "        This function returns the portfolio weights, performance statistics, ESG performance, and sector analysis of each portfolio\n",
    "\n",
    "        Parameters:\n",
    "            base_optimizer (object): Instance of the BaseConvexOptimizer class to solve the optimisation problem\n",
    "            num_random_tickers_each_sector (int): Number of initial random tickers to select from each sector\n",
    "            portfolios_list (list): Names of the portfolios\n",
    "\n",
    "        Returns:\n",
    "            None. This method prints out the portfolio statistics, ESG performance, and sector composition of each portfolio\n",
    "        \"\"\"\n",
    "        financial_environmental_data = self.data_etl()\n",
    "        financial_stock_data = self.process_stock_price_data()\n",
    "        final_data = self.group_data_by_sector(financial_environmental_data, financial_stock_data)\n",
    "        random_tickers = self.get_random_tickers(final_data, num_random_tickers_each_sector)\n",
    "        random_tickers = random_tickers.dropna()\n",
    "        df_final, stock_prices = self.get_final_data(random_tickers, financial_environmental_data, financial_stock_data)\n",
    "        descriptive_statistics = self.get_descriptive_statistics(df_final, stock_prices)\n",
    "        \n",
    "        print(\"----------BENCHMARK PORTFOLIO: MARKET CAP-WEIGHTED PORTFOLIO----------\\n\")\n",
    "        benchmark_portfolio, benchmark_perf, benchmark_scores = self.market_cap_portfolio(df_final, descriptive_statistics['mu'], descriptive_statistics['S'])\n",
    "        benchmark_weights = benchmark_portfolio['Weights'].values\n",
    "        carbon_intensity = df_final['Carbon Intensity'].values\n",
    "        total_initial_carbon_intensity = (benchmark_weights * carbon_intensity).sum()\n",
    "        print(\"----------DECARBONISED PORTFOLIO 1 (reduction by 50%)----------\\n\")\n",
    "        dcp_1_weights, dcp1_perf, dcp_1_scores = self.decarbonised_portfolio(total_initial_carbon_intensity, 0.5, base_optimizer, \n",
    "                                                            stock_prices, descriptive_statistics['mu'], \n",
    "                                                            descriptive_statistics['S'], carbon_intensity, df_final, benchmark_weights)\n",
    "        print(\"----------DECARBONISED PORTFOLIO 2 (reductiion by 25%)----------\\n\")\n",
    "        dcp_2_weights, dcp2_perf, dcp_2_scores = self.decarbonised_portfolio(total_initial_carbon_intensity, 0.25, base_optimizer, \n",
    "                                                            stock_prices, descriptive_statistics['mu'], \n",
    "                                                            descriptive_statistics['S'], carbon_intensity, df_final, benchmark_weights)\n",
    "        print(\"----------DECARBONISED PORTFOLIO 3 (reduction by 10%)----------\\n\")\n",
    "        dcp_3_weights, dcp3_perf, dcp_3_scores = self.decarbonised_portfolio(total_initial_carbon_intensity, 0.1, base_optimizer, \n",
    "                                                            stock_prices, descriptive_statistics['mu'], \n",
    "                                                            descriptive_statistics['S'], carbon_intensity, df_final, benchmark_weights)\n",
    "        print(\"----------DECARBONISED PORTFOLIO 4 (reduction by 50%, sector balance)----------\\n\")\n",
    "        dcp_4_weights, dcp4_perf, dcp_4_scores = self.decarbonised_portfolio(total_initial_carbon_intensity, 0.5, base_optimizer,\n",
    "                                                            stock_prices, descriptive_statistics['mu'], \n",
    "                                                            descriptive_statistics['S'], carbon_intensity, \n",
    "                                                            df_final, benchmark_weights, random_tickers, is_sector_balance_portfolio=True)\n",
    "        print(\"----------MEAN-VARIANCE EFFICIENT PORTFOLIO----------\\n\")\n",
    "        mvp_weights, mvp_perf, mvp_scores = self.mean_variance_efficient_portfolio(descriptive_statistics['mu'], descriptive_statistics['S'], \n",
    "                                                                df_final, is_decarbonised=False)\n",
    "        print(\"----------MEAN-VARIANCE EFFICIENT PORTFOLIO: DECARBONISED PORTFOLIO 5 (reduction by 50%)----------\\n\")\n",
    "        mvp_dcp_5_weights, mvp_dcp_5_perf, mvp_dcp_5_scores = self.mean_variance_efficient_portfolio(descriptive_statistics['mu'], descriptive_statistics['S'],\n",
    "                                                                                df_final, total_initial_carbon_intensity, \n",
    "                                                                                carbon_intensity, intensity_reduction_rate=0.5, is_decarbonised=True)\n",
    "        print(\"----------ESG PERFORMANCE STATS----------\\n\")\n",
    "        print(self.create_esg_performance_df(benchmark_scores, dcp_1_scores, dcp_2_scores, dcp_3_scores, \n",
    "                                           dcp_4_scores, mvp_scores, mvp_dcp_5_scores, portfolios_list))\n",
    "        print(\"----------SECTOR/INDUSTRY COMPOSITION FOR ALL CONSTRUCTED PORTFOLIOS----------\\n\")\n",
    "        sector_composition_companies, sector_composition_grouped = self.sector_analysis(benchmark_portfolio, \n",
    "                                                                                                dcp_1_weights, dcp_2_weights, \n",
    "                                                                                                dcp_3_weights, dcp_4_weights, \n",
    "                                                                                                mvp_weights, mvp_dcp_5_weights)\n",
    "\n",
    "        print(\"\\n Sector Analysis by company\")\n",
    "        print(sector_composition_companies)\n",
    "        print(\"\\n Sector Analysis by group\")\n",
    "        print(sector_composition_grouped)\n",
    "\n",
    "        portfolio_stats_df = pd.DataFrame(index=portfolios_list)\n",
    "        portfolio_stats_df['Companies Invested'] = [benchmark_perf['Num_Companies'], dcp1_perf['Num_Companies'], dcp2_perf['Num_Companies'], dcp3_perf['Num_Companies'], dcp4_perf['Num_Companies'], mvp_perf['Num_Companies'], mvp_dcp_5_perf['Num_Companies']]\n",
    "        portfolio_stats_df['Annual ExpReturn'] = [benchmark_perf['Annualised_ExpReturn'], dcp1_perf['Annualised_ExpReturn'], dcp2_perf['Annualised_ExpReturn'], dcp3_perf['Annualised_ExpReturn'], dcp4_perf['Annualised_ExpReturn'], mvp_perf['Annualised_ExpReturn'], mvp_dcp_5_perf['Annualised_ExpReturn']]\n",
    "        portfolio_stats_df['Monthly ExpReturn'] = portfolio_stats_df['Annual ExpReturn']/12\n",
    "        portfolio_stats_df['Annual Volatility'] = [benchmark_perf['Annualised_Volatility'], dcp1_perf['Annualised_Volatility'], dcp2_perf['Annualised_Volatility'], dcp3_perf['Annualised_Volatility'], dcp4_perf['Annualised_Volatility'], mvp_perf['Annualised_Volatility'], mvp_dcp_5_perf['Annualised_Volatility']]\n",
    "        portfolio_stats_df['Monthly Volatility'] = portfolio_stats_df['Annual Volatility']/np.sqrt(12)\n",
    "        portfolio_stats_df['Sharpe Ratio'] = [benchmark_perf['Sharpe_Ratio'], dcp1_perf['Sharpe_Ratio'], dcp2_perf['Sharpe_Ratio'], dcp3_perf['Sharpe_Ratio'], dcp4_perf['Sharpe_Ratio'], mvp_perf['Sharpe_Ratio'], mvp_dcp_5_perf['Sharpe_Ratio']]\n",
    "        # portfolio_stats_df['Annual StdDev'] = np.sqrt(portfolio_stats_df['Volatility'])\n",
    "        # portfolio_stats_df['Monthly StdDev'] = portfolio_stats_df['Annual StdDev']/np.sqrt(12)\n",
    "        print(\"\\n----------PORTFOLIO ANALYSIS----------\\n\")\n",
    "        print(portfolio_stats_df)\n",
    "    \n",
    "    def run_portfolio_decarbonisation(self, base_optimizer):\n",
    "        \"\"\"\n",
    "        Runs the portfolio decarbonisation process. This function creates and analyses various types of portfolios \n",
    "        and displays the ESG performance and sector analysis of each portfolio\n",
    "\n",
    "        Parameters:\n",
    "            base_optimizer (object): Instance of the BaseConvexOptimizer class to solve the optimisation problem.\n",
    "\n",
    "        Returns:\n",
    "            None. This method prints out the portfolio statistics, ESG performance, and sector composition of each portfolio.\n",
    "        \"\"\"\n",
    "        portfolios_list = ['Benchmark Market Cap-Based Portfolio', 'Decarbonised Portfolio1 (reduction by 50%)',\n",
    "                            'Decarbonised Portfolio2 (reduction by 25%)', 'Decarbonised Portfolio3 (reduction by 10%)',\n",
    "                            'Decarbonised Portfolio4 (50%, Sector-Balanced)', 'Mean-Variance Portfolio',\n",
    "                            'Decarbonised Mean-Variance Portfolio (reduction by 50%)']\n",
    "        self.create_and_analyze_portfolios(base_optimizer, 6, portfolios_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f70ee9f",
   "metadata": {
    "code_folding": [],
    "run_control": {
     "marked": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RSK: df_final:                    Scope1  Scope2Location  Scope2Market     Scope3  ESG Score  \\\n",
      "Ticker                                                                          \n",
      "AA UN Equity    17400.000        4400.000      6439.190  47500.000    80.9878   \n",
      "ABBV UN Equity    342.607         271.055       184.549   8544.660    68.7355   \n",
      "ABT UN Equity     533.000         478.000       397.000  12480.000    76.6522   \n",
      "ADBE UW Equity      6.568          57.168        22.936    463.437    66.7337   \n",
      "AJG UN Equity      14.662          32.397           NaN     72.650    36.0024   \n",
      "\n",
      "                Environmental Score  Governance Score  Social Score  \\\n",
      "Ticker                                                                \n",
      "AA UN Equity                80.6403          100.0000       62.2430   \n",
      "ABBV UN Equity              53.7300          100.0000       52.3579   \n",
      "ABT UN Equity               74.7810           97.5015       57.5877   \n",
      "ADBE UW Equity              65.0861           91.2402       43.7727   \n",
      "AJG UN Equity                5.6780           84.9789       17.1705   \n",
      "\n",
      "                  MarketCap  Revenue             GICS Sector  Carbon Intensity  \n",
      "Ticker                                                                          \n",
      "AA UN Equity      8046.7846  12451.0               Materials          1.750863  \n",
      "ABBV UN Equity  285917.3889  58054.0             Health Care          0.010571  \n",
      "ABT UN Equity   190792.5154  43653.0             Health Care          0.023160  \n",
      "ADBE UW Equity  157786.8600  17606.0  Information Technology          0.003620  \n",
      "AJG UN Equity    39951.6260   8550.6              Financials          0.005504  \n",
      "RSK: stock_prices: Ticker      AA UN Equity  ABBV UN Equity  ABT UN Equity  ADBE UW Equity  \\\n",
      "Dates                                                                     \n",
      "2017-01-31         36.45           61.11          41.77          113.38   \n",
      "2017-02-28         34.59           61.84          45.08          118.34   \n",
      "2017-03-31         34.40           65.16          44.41          130.13   \n",
      "2017-04-28         33.73           65.94          43.64          133.74   \n",
      "2017-05-31         32.94           66.02          45.66          141.86   \n",
      "\n",
      "Ticker      AJG UN Equity  APAM UN Equity  APD UN Equity  ARCB UW Equity  \\\n",
      "Dates                                                                      \n",
      "2017-01-31          53.83           28.95         139.76           31.60   \n",
      "2017-02-28          56.95           28.45         140.47           29.35   \n",
      "2017-03-31          56.54           27.60         135.29           26.00   \n",
      "2017-04-28          55.81           29.30         140.50           26.45   \n",
      "2017-05-31          56.73           28.30         144.06           18.80   \n",
      "\n",
      "Ticker      ARMK UN Equity  AWK UN Equity  ...  TDY UN Equity  TTWO UW Equity  \\\n",
      "Dates                                      ...                                  \n",
      "2017-01-31           33.84          73.44  ...         122.87           53.65   \n",
      "2017-02-28           35.74          78.00  ...         131.41           56.98   \n",
      "2017-03-31           36.87          77.77  ...         126.46           59.27   \n",
      "2017-04-28           36.52          79.76  ...         134.83           62.85   \n",
      "2017-05-31           37.26          78.18  ...         131.51           76.74   \n",
      "\n",
      "Ticker      TUP UN Equity  VMI UN Equity  WBA UW Equity  WDC UW Equity  \\\n",
      "Dates                                                                    \n",
      "2017-01-31          60.36         144.00          81.94          79.73   \n",
      "2017-02-28          60.39         157.25          86.38          76.88   \n",
      "2017-03-31          62.72         155.50          83.05          82.53   \n",
      "2017-04-28          71.81         152.35          86.54          89.07   \n",
      "2017-05-31          71.91         146.40          81.02          90.06   \n",
      "\n",
      "Ticker      WLY UN Equity  WTI UN Equity  WY UN Equity  WYNN UW Equity  \n",
      "Dates                                                                   \n",
      "2017-01-31           55.1           2.90         31.33          101.43  \n",
      "2017-02-28           52.2           2.51         33.72           96.15  \n",
      "2017-03-31           53.8           2.77         33.98          114.61  \n",
      "2017-04-28           52.7           2.04         33.87          123.01  \n",
      "2017-05-31           50.7           2.04         32.96          128.70  \n",
      "\n",
      "[5 rows x 100 columns]\n",
      "----------BENCHMARK PORTFOLIO: MARKET CAP-WEIGHTED PORTFOLIO----------\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot reindex on an axis with duplicate labels",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m risk_free_rate \u001b[39m=\u001b[39m \u001b[39m0.0009\u001b[39m\n\u001b[1;32m      7\u001b[0m PD \u001b[39m=\u001b[39m PortfolioDecarbonisation(\u001b[39m'\u001b[39m\u001b[39m./data/R3000_V02.xlsx\u001b[39m\u001b[39m'\u001b[39m, risk_free_rate\u001b[39m=\u001b[39mrisk_free_rate)\n\u001b[0;32m----> 8\u001b[0m PD\u001b[39m.\u001b[39;49mrun_portfolio_decarbonisation(base_optimizer\u001b[39m=\u001b[39;49mbase_optimizer)   \n",
      "Cell \u001b[0;32mIn[2], line 776\u001b[0m, in \u001b[0;36mPortfolioDecarbonisation.run_portfolio_decarbonisation\u001b[0;34m(self, base_optimizer)\u001b[0m\n\u001b[1;32m    762\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    763\u001b[0m \u001b[39mRuns the portfolio decarbonisation process. This function creates and analyses various types of portfolios \u001b[39;00m\n\u001b[1;32m    764\u001b[0m \u001b[39mand displays the ESG performance and sector analysis of each portfolio\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    770\u001b[0m \u001b[39m    None. This method prints out the portfolio statistics, ESG performance, and sector composition of each portfolio.\u001b[39;00m\n\u001b[1;32m    771\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    772\u001b[0m portfolios_list \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39mBenchmark Market Cap-Based Portfolio\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mDecarbonised Portfolio1 (reduction by 50\u001b[39m\u001b[39m%\u001b[39m\u001b[39m)\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m    773\u001b[0m                     \u001b[39m'\u001b[39m\u001b[39mDecarbonised Portfolio2 (reduction by 25\u001b[39m\u001b[39m%\u001b[39m\u001b[39m)\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mDecarbonised Portfolio3 (reduction by 10\u001b[39m\u001b[39m%\u001b[39m\u001b[39m)\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m    774\u001b[0m                     \u001b[39m'\u001b[39m\u001b[39mDecarbonised Portfolio4 (50\u001b[39m\u001b[39m%\u001b[39m\u001b[39m, Sector-Balanced)\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mMean-Variance Portfolio\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m    775\u001b[0m                     \u001b[39m'\u001b[39m\u001b[39mDecarbonised Mean-Variance Portfolio (reduction by 50\u001b[39m\u001b[39m%\u001b[39m\u001b[39m)\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m--> 776\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcreate_and_analyze_portfolios(base_optimizer, \u001b[39m6\u001b[39;49m, portfolios_list)\n",
      "Cell \u001b[0;32mIn[2], line 707\u001b[0m, in \u001b[0;36mPortfolioDecarbonisation.create_and_analyze_portfolios\u001b[0;34m(self, base_optimizer, num_random_tickers_each_sector, portfolios_list)\u001b[0m\n\u001b[1;32m    704\u001b[0m descriptive_statistics \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_descriptive_statistics(df_final, stock_prices)\n\u001b[1;32m    706\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m----------BENCHMARK PORTFOLIO: MARKET CAP-WEIGHTED PORTFOLIO----------\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 707\u001b[0m benchmark_portfolio, benchmark_perf, benchmark_scores \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmarket_cap_portfolio(df_final, descriptive_statistics[\u001b[39m'\u001b[39;49m\u001b[39mmu\u001b[39;49m\u001b[39m'\u001b[39;49m], descriptive_statistics[\u001b[39m'\u001b[39;49m\u001b[39mS\u001b[39;49m\u001b[39m'\u001b[39;49m])\n\u001b[1;32m    708\u001b[0m benchmark_weights \u001b[39m=\u001b[39m benchmark_portfolio[\u001b[39m'\u001b[39m\u001b[39mWeights\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mvalues\n\u001b[1;32m    709\u001b[0m carbon_intensity \u001b[39m=\u001b[39m df_final[\u001b[39m'\u001b[39m\u001b[39mCarbon Intensity\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mvalues\n",
      "Cell \u001b[0;32mIn[2], line 434\u001b[0m, in \u001b[0;36mPortfolioDecarbonisation.market_cap_portfolio\u001b[0;34m(self, df_final, mu, S)\u001b[0m\n\u001b[1;32m    422\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmarket_cap_portfolio\u001b[39m(\u001b[39mself\u001b[39m, df_final, mu, S):\n\u001b[1;32m    423\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    424\u001b[0m \u001b[39m    Calculate market cap weighted portfolio, its performance metrics, and ESG scores\u001b[39;00m\n\u001b[1;32m    425\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    432\u001b[0m \u001b[39m        Tuple: A tuple containing portfolio weights DataFrame, performance dictionary, and ESG scores dictionary\u001b[39;00m\n\u001b[1;32m    433\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 434\u001b[0m     benchmark_portfolio \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_benchmark_portfolio(df_final, mu)\n\u001b[1;32m    435\u001b[0m     benchmark_performance \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_portfolio_performance(benchmark_portfolio, mu, S)\n\u001b[1;32m    436\u001b[0m     benchmark_scores \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_portfolio_scores(benchmark_portfolio, df_final, is_benchmark\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn[2], line 337\u001b[0m, in \u001b[0;36mPortfolioDecarbonisation.get_benchmark_portfolio\u001b[0;34m(self, df_final, mu)\u001b[0m\n\u001b[1;32m    335\u001b[0m benchmark_portfolio[\u001b[39m'\u001b[39m\u001b[39mGICS Sector\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m market_cap[\u001b[39m'\u001b[39m\u001b[39mGICS Sector\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m    336\u001b[0m benchmark_portfolio[\u001b[39m'\u001b[39m\u001b[39mWeights\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m market_cap[\u001b[39m'\u001b[39m\u001b[39mMarketCap\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m/\u001b[39mmarket_cap[\u001b[39m'\u001b[39m\u001b[39mMarketCap\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39msum()\n\u001b[0;32m--> 337\u001b[0m benchmark_portfolio[\u001b[39m'\u001b[39;49m\u001b[39mExpStockReturns\u001b[39;49m\u001b[39m'\u001b[39;49m] \u001b[39m=\u001b[39m mu \u001b[39m*\u001b[39m benchmark_portfolio[\u001b[39m'\u001b[39m\u001b[39mWeights\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m    338\u001b[0m portfolio_scores \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39mCarbon Intensity\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mESG Score\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mEnvironmental Score\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mSocial Score\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mGovernance Score\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m    339\u001b[0m \u001b[39mfor\u001b[39;00m score \u001b[39min\u001b[39;00m portfolio_scores:\n",
      "File \u001b[0;32m~/miniconda3/envs/gds_conda/lib/python3.10/site-packages/pandas/core/frame.py:3950\u001b[0m, in \u001b[0;36mDataFrame.__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3947\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_setitem_array([key], value)\n\u001b[1;32m   3948\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   3949\u001b[0m     \u001b[39m# set column\u001b[39;00m\n\u001b[0;32m-> 3950\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_set_item(key, value)\n",
      "File \u001b[0;32m~/miniconda3/envs/gds_conda/lib/python3.10/site-packages/pandas/core/frame.py:4143\u001b[0m, in \u001b[0;36mDataFrame._set_item\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   4133\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_set_item\u001b[39m(\u001b[39mself\u001b[39m, key, value) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   4134\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   4135\u001b[0m \u001b[39m    Add series to DataFrame in specified column.\u001b[39;00m\n\u001b[1;32m   4136\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4141\u001b[0m \u001b[39m    ensure homogeneity.\u001b[39;00m\n\u001b[1;32m   4142\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 4143\u001b[0m     value \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sanitize_column(value)\n\u001b[1;32m   4145\u001b[0m     \u001b[39mif\u001b[39;00m (\n\u001b[1;32m   4146\u001b[0m         key \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\n\u001b[1;32m   4147\u001b[0m         \u001b[39mand\u001b[39;00m value\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m   4148\u001b[0m         \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m is_extension_array_dtype(value)\n\u001b[1;32m   4149\u001b[0m     ):\n\u001b[1;32m   4150\u001b[0m         \u001b[39m# broadcast across multiple columns if necessary\u001b[39;00m\n\u001b[1;32m   4151\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mis_unique \u001b[39mor\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns, MultiIndex):\n",
      "File \u001b[0;32m~/miniconda3/envs/gds_conda/lib/python3.10/site-packages/pandas/core/frame.py:4867\u001b[0m, in \u001b[0;36mDataFrame._sanitize_column\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m   4865\u001b[0m     \u001b[39mreturn\u001b[39;00m _reindex_for_setitem(value, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex)\n\u001b[1;32m   4866\u001b[0m \u001b[39melif\u001b[39;00m is_dict_like(value):\n\u001b[0;32m-> 4867\u001b[0m     \u001b[39mreturn\u001b[39;00m _reindex_for_setitem(Series(value), \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mindex)\n\u001b[1;32m   4869\u001b[0m \u001b[39mif\u001b[39;00m is_list_like(value):\n\u001b[1;32m   4870\u001b[0m     com\u001b[39m.\u001b[39mrequire_length_match(value, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex)\n",
      "File \u001b[0;32m~/miniconda3/envs/gds_conda/lib/python3.10/site-packages/pandas/core/frame.py:11615\u001b[0m, in \u001b[0;36m_reindex_for_setitem\u001b[0;34m(value, index)\u001b[0m\n\u001b[1;32m  11611\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m  11612\u001b[0m     \u001b[39m# raised in MultiIndex.from_tuples, see test_insert_error_msmgs\u001b[39;00m\n\u001b[1;32m  11613\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m value\u001b[39m.\u001b[39mindex\u001b[39m.\u001b[39mis_unique:\n\u001b[1;32m  11614\u001b[0m         \u001b[39m# duplicate axis\u001b[39;00m\n\u001b[0;32m> 11615\u001b[0m         \u001b[39mraise\u001b[39;00m err\n\u001b[1;32m  11617\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[1;32m  11618\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mincompatible index of inserted column with frame index\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m  11619\u001b[0m     ) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m  11620\u001b[0m \u001b[39mreturn\u001b[39;00m reindexed_value\n",
      "File \u001b[0;32m~/miniconda3/envs/gds_conda/lib/python3.10/site-packages/pandas/core/frame.py:11610\u001b[0m, in \u001b[0;36m_reindex_for_setitem\u001b[0;34m(value, index)\u001b[0m\n\u001b[1;32m  11608\u001b[0m \u001b[39m# GH#4107\u001b[39;00m\n\u001b[1;32m  11609\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m> 11610\u001b[0m     reindexed_value \u001b[39m=\u001b[39m value\u001b[39m.\u001b[39;49mreindex(index)\u001b[39m.\u001b[39m_values\n\u001b[1;32m  11611\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m  11612\u001b[0m     \u001b[39m# raised in MultiIndex.from_tuples, see test_insert_error_msmgs\u001b[39;00m\n\u001b[1;32m  11613\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m value\u001b[39m.\u001b[39mindex\u001b[39m.\u001b[39mis_unique:\n\u001b[1;32m  11614\u001b[0m         \u001b[39m# duplicate axis\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/gds_conda/lib/python3.10/site-packages/pandas/core/series.py:4918\u001b[0m, in \u001b[0;36mSeries.reindex\u001b[0;34m(self, index, axis, method, copy, level, fill_value, limit, tolerance)\u001b[0m\n\u001b[1;32m   4901\u001b[0m \u001b[39m@doc\u001b[39m(\n\u001b[1;32m   4902\u001b[0m     NDFrame\u001b[39m.\u001b[39mreindex,  \u001b[39m# type: ignore[has-type]\u001b[39;00m\n\u001b[1;32m   4903\u001b[0m     klass\u001b[39m=\u001b[39m_shared_doc_kwargs[\u001b[39m\"\u001b[39m\u001b[39mklass\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4916\u001b[0m     tolerance\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   4917\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Series:\n\u001b[0;32m-> 4918\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mreindex(\n\u001b[1;32m   4919\u001b[0m         index\u001b[39m=\u001b[39;49mindex,\n\u001b[1;32m   4920\u001b[0m         method\u001b[39m=\u001b[39;49mmethod,\n\u001b[1;32m   4921\u001b[0m         copy\u001b[39m=\u001b[39;49mcopy,\n\u001b[1;32m   4922\u001b[0m         level\u001b[39m=\u001b[39;49mlevel,\n\u001b[1;32m   4923\u001b[0m         fill_value\u001b[39m=\u001b[39;49mfill_value,\n\u001b[1;32m   4924\u001b[0m         limit\u001b[39m=\u001b[39;49mlimit,\n\u001b[1;32m   4925\u001b[0m         tolerance\u001b[39m=\u001b[39;49mtolerance,\n\u001b[1;32m   4926\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/gds_conda/lib/python3.10/site-packages/pandas/core/generic.py:5360\u001b[0m, in \u001b[0;36mNDFrame.reindex\u001b[0;34m(self, labels, index, columns, axis, method, copy, level, fill_value, limit, tolerance)\u001b[0m\n\u001b[1;32m   5357\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reindex_multi(axes, copy, fill_value)\n\u001b[1;32m   5359\u001b[0m \u001b[39m# perform the reindex on the axes\u001b[39;00m\n\u001b[0;32m-> 5360\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_reindex_axes(\n\u001b[1;32m   5361\u001b[0m     axes, level, limit, tolerance, method, fill_value, copy\n\u001b[1;32m   5362\u001b[0m )\u001b[39m.\u001b[39m__finalize__(\u001b[39mself\u001b[39m, method\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mreindex\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/gds_conda/lib/python3.10/site-packages/pandas/core/generic.py:5375\u001b[0m, in \u001b[0;36mNDFrame._reindex_axes\u001b[0;34m(self, axes, level, limit, tolerance, method, fill_value, copy)\u001b[0m\n\u001b[1;32m   5372\u001b[0m     \u001b[39mcontinue\u001b[39;00m\n\u001b[1;32m   5374\u001b[0m ax \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_axis(a)\n\u001b[0;32m-> 5375\u001b[0m new_index, indexer \u001b[39m=\u001b[39m ax\u001b[39m.\u001b[39;49mreindex(\n\u001b[1;32m   5376\u001b[0m     labels, level\u001b[39m=\u001b[39;49mlevel, limit\u001b[39m=\u001b[39;49mlimit, tolerance\u001b[39m=\u001b[39;49mtolerance, method\u001b[39m=\u001b[39;49mmethod\n\u001b[1;32m   5377\u001b[0m )\n\u001b[1;32m   5379\u001b[0m axis \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_axis_number(a)\n\u001b[1;32m   5380\u001b[0m obj \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39m_reindex_with_indexers(\n\u001b[1;32m   5381\u001b[0m     {axis: [new_index, indexer]},\n\u001b[1;32m   5382\u001b[0m     fill_value\u001b[39m=\u001b[39mfill_value,\n\u001b[1;32m   5383\u001b[0m     copy\u001b[39m=\u001b[39mcopy,\n\u001b[1;32m   5384\u001b[0m     allow_dups\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m   5385\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/gds_conda/lib/python3.10/site-packages/pandas/core/indexes/base.py:4275\u001b[0m, in \u001b[0;36mIndex.reindex\u001b[0;34m(self, target, method, level, limit, tolerance)\u001b[0m\n\u001b[1;32m   4272\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mcannot handle a non-unique multi-index!\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   4273\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mis_unique:\n\u001b[1;32m   4274\u001b[0m     \u001b[39m# GH#42568\u001b[39;00m\n\u001b[0;32m-> 4275\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mcannot reindex on an axis with duplicate labels\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   4276\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   4277\u001b[0m     indexer, _ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_indexer_non_unique(target)\n",
      "\u001b[0;31mValueError\u001b[0m: cannot reindex on an axis with duplicate labels"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    \"\"\"\n",
    "    This is the main function which instantiates the PortfolioDecarbonisation class \n",
    "    with a specified data source and runs the portfolio decarbonisation process\n",
    "    \"\"\"\n",
    "    risk_free_rate = 0.0009\n",
    "    PD = PortfolioDecarbonisation('./data/R3000_V02.xlsx', risk_free_rate=risk_free_rate)\n",
    "    PD.run_portfolio_decarbonisation(base_optimizer=base_optimizer)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee5976dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3a378a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gds_conda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
